tail(DF[-37],1)
setwd("/Users/garfield/peer")
getwd()
setwd("./peer2")
DF<-read.csv("repdata-data-StormData.csv.bz2")
tail(DF[-37],1)
tail(DF[-36],1)
setwd("/Users/garfield/peer")
getwd()
str(DF$FATALITIES)
str(DF$INJURIES)
str(DF$PROPDMG)
str(DF$CROPDMG)
setwd("/Users/garfield/peer")
getwd()
set(./peer2)
getset(./peer2)
setwd(./peer2)
setwd(~/peer2)
setwd("./peer2")
getwe()
getwd()
setwd("./peer2")
getwd()
library(manipulate)
pvals<-seq(0.01,0.99,length=1000)
dbeta(pvals,alpha,beta)
slider(0.01,10,initial=1,step=.5)
manipulate(
plot(pvals,dbeta(pvals,alpha,beta),type="l",lwd=3,frame=FALSE),
alpha=slider(0.01,10,initial=1,step=.5),
beta=slider(0.01,10,initial=1,step=.5)
)
dbeta(pvals,alpha,beta)
manipulate(
plot(cars, xlim=c(x.min,x.max)),
x.min=slider(0,15),
x.max=slider(15,30))
??binom.bayes
library(binom)
install.packages(binom)
library("binom")
install.packages("binom")
library("binom")
x<-13;n<-20
myPlot2<-function(alpha,beta,cl){
plot(pvals,dbeta(pvals,alpha+x,beta+(n-x)),type="l",lwd=3,
xlab="p",ylab="",frame=FALSE)
out<-binom.bayes(x,n,type="highest",
prior.shape1=alpha,
prior.shape2=beta,
conf.level=cl)
p1<-out$lower;p2<-out$upper
lines(c(p1,p1,p2,p2),c(0,dbeta(c(p1,p2),alpha+x,beta+(n-x)),0),
type="l",lwd=3,col="darkred")
}
manipulate(
myPlot2(alpha,beta,cl),
alpha=slider(0.01,10,initial=1,step=.5),
beta=slider(0.01,10,initial=1,step=.5),
cl=slider(0.01,0.99,initial=0.95,step=.01)
)
u<-1100
sd<-30
n<-9
u+c(-1,1)*qt(0.975)*sd/sqrt(n)
u+c(-1,1)*qt(0.975,n-1)*sd/sqrt(n-1)
u+c(-1,1)*qt(0.975,n)*sd/sqrt(n)
-2/(-qt(0.95,9))
qt(0.95,9)
-2*3/(-qt(0.95,9))
-2*3/2.6
-qt(0.95,9)
-2*3/(-qt(0.975,9))
-qt(0.975,9)
-2*3/2.6
u1<-3;sd1<-sqrt(0.6)
u2<-5;sd2<-sqrt(0.68)
n1<-10;n2<-10
sp<-((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2)
u1-u2+c(-1,1)*qt(0.975,(n1+n2-2))*sp/sqrt(1/n1+1/n2)
sp<-sqrt(((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
u1-u2+c(-1,1)*qt(0.975,(n1+n2-2))*sp/sqrt(1/n1+1/n2)
sp<-sqrt(((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
sp<-sqrt((9*sd1^2+9*sd2^2)/18)
u1-u2
+
c(-1,1)*qt(0.975,18)*sp/(1/10+1/10)^0.5
u1-u2+c(-1,1)*qt(0.975,18)*sp/(1/10+1/10)^0.5
u2<-5;sd2<-0.68
sp<-sqrt((9*sd1^2+9*sd2^2)/18)
u1-u2+c(-1,1)*qt(0.975,18)*sp/(1/10+1/10)^0.5
u1<-3;sd1<-0.6
u2<-5;sd2<-0.68
n1<-10;n2<-10
sp<-sqrt((9*sd1^2+9*sd2^2)/18)
u1-u2+c(-1,1)*qt(0.975,18)*sp/(1/10+1/10)^0.5
sp<-sqrt((9*sd1+9*sd2)/18)
u1-u2+c(-1,1)*qt(0.975,18)*sp/(1/10+1/10)^0.5
u1-u2+c(-1,1)*qt(0.975,18)*sp*(1/10+1/10)^0.5
u1-u2+c(-1,1)*qt(0.975,18)*sp/sqrt(1/10+1/10)
u1<-6;sd1<-(2)^2
u2<-4;sd2<-(o.5)^2
n1<-100;n2<-100
sp<-sqrt(((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
u1-u2+c(-1,1)*qt(0.975,(n1+n2-2))*sp*(1/100+1/100)^0.5
u1<--3;sd1<-(1.5)^2
u2<-1;sd2<-(1.8)^2
n1<-9;n2<-9
sp<-sqrt(((n1-1)*sd1^2+(n2-1)*sd2^2)/(n1+n2-2))
u1-u2+c(-1,1)*qt(0.95,(n1+n2-2))*sp*(1/n1+1/n2)^0.5
u1<--3;sd1<-(1.5)^2
u2<-1;sd2<-(1.8)^2
n1<-9;n2<-9
sp<-sqrt(((n1-1)*sd1+(n2-1)*sd2)/(n1+n2-2))
u1-u2+c(-1,1)*qt(0.95,(n1+n2-2))*sp*(1/n1+1/n2)^0.5
u1<--4;sd1<-(0.5)^2
u2<-6;sd2<-(2)^2
n1<-100;n2<-100
sp<-sqrt(((n1-1)*sd1+(n2-1)*sd2)/(n1+n2-2))
u1-u2+c(-1,1)*qt(0.95,(n1+n2-2))*sp*(1/n1+1/n2)^0.5
DF<-data.frame(a=c(13,400,699),b=c("testtesttest","lotalotlaotlaot","nobodynobodynobody"))
View(DF)
barplot(DF$b,names.arg =DF$a)
barplot(DF$b[1:3],names.arg =DF$a[1:3])
DF$b[1:3]
barplot(DF$a[1:3],names.arg =DF$b[1:3])
DF<-data.frame(a=c(13,400,699,1000,10000),
b=c("testtesttest","lotalotlaotlaot","nobodynobodynobody"
,"tbodynobodynobody","blbodynobodynobody"))
barplot(DF$a[1:3],names.arg =DF$b[1:3])
barplot(DF$a,names.arg =DF$b)
DF<-data.frame(a=c(13,400,699,1000,10000,1999,3999),
b=c("testtesttest","lotalotlaotlaot","nobodynobodynobody"
,"tbodynobodynobody","blbodynobodynobody","ccbodynobodynobody"
,"dstadegbdesssg","dstadegedg","dadegbdesssg"))
DF<-data.frame(a=c(13,400,699,1000,10000,1999,3999,1234,456),
b=c("testtesttest","lotalotlaotlaot","nobodynobodynobody"
,"tbodynobodynobody","blbodynobodynobody","ccbodynobodynobody"
,"dstadegbdesssg","dstadegedg","dadegbdesssg"))
barplot(DF$a,names.arg =DF$b)
barplot(DF$a,names.arg =DF$b,las=2)
barplot(DF$a,names.arg =DF$b,las=3)
barplot(DF$a,names.arg =DF$b,las=2)
barplot(DF$a,names.arg =DF$b,las=1)
barplot(DF$a,names.arg =DF$b,las=4)
barplot(DF$a,names.arg =DF$b,las=1)
barplot(DF$a,names.arg =DF$b,las=2)
barplot(DF$a,names.arg =DF$b,las=3)
barplot(DF$a,names.arg =DF$b,las=1)
barplot(DF$a,names.arg =DF$b,las=2)
barplot(DF$a,names.arg =DF$b,las=3)
a<-c("h","H","m","M","b","B")
as.numeric(a)
as.numeric(a)
5*as.numeric(a)
?destiy
?density
x <- c(0.8, 0.47, 0.51, 0.73, 0.36, 0.58, 0.57, 0.85, 0.44, 0.42)
y <- c(1.39, 0.72, 1.55, 0.48, 1.19, -1.59, 1.23, -0.65, 1.49, 0.05)
l<-lm(y~x-1)
str(l)
l<-lm(y~x)
str(l)
predict.lm(y~x)
plot(x,y)
library(kernlab)
library(kernlab)
install.packages("kernlab")
library(kernlab)
data(spam)
nrow(spam)
names(spam)
table(spam$your)
spam$type="spam"
spam$type=="spam"
spam$your[spam$type=="spam"]
spam$your[spam$type=="nospam"]
spam$type
table(spam$type)
density(spam$your[spam$type=="nospam"])
density(spam$your[spam$type=="nospam"])
data(spam)
density(spam$your[spam$type=="nospam"])
library(kernlab)
data(spam)
spam$your[spam$type=="nospam"]
install.packages("kernlab")
install.packages("kernlab")
library(kernlab)
table(spam$type)
density(spam$your[spam$type=="nospam"])
table(spam$type)
spam$your[spam$type=="nospam"]
density(spam$your)
spam$your[spam$type=="nospam"]
spam$type=="nospam"
table(spam$type)
spam[spam$type=="nospam"]$your
spam[spam$type=="nospam","your"]
spam[spam$type=="nonspam","your"]
spam$type=="spam","your"]
s
spam$your[spam$type=="spam"]
length(spam$your[spam$type=="spam"])
table(spam$your[spam$type=="spam"])
347/1813
density(spam$your[spam$type=="spam"])
length(density(spam$your[spam$type=="spam"]))
class(density(spam$your[spam$type=="spam"]))
str(density(spam$your[spam$type=="spam"]))
library(caret);
install.packages("AppliedPredictiveModeling")
edPredictiveModeling
library("AppliedPredictiveModeling")
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
set.seed(3433)
data(AlzheimerDisease)
adData = data.frame(diagnosis,predictors)
inTrain = createDataPartition(adData$diagnosis, p = 3/4)[[1]]
training = adData[ inTrain,]
testing = adData[-inTrain,]
Ilname<-grep("^IL",names(training),perl=TRUE)
newtraining<-training[Ilname,]
newtraining<-training[,Ilname]
pcatr<-preProcess(newtraining,method="pca",pcaComp=11)
pranew<-predict(pcatr,newtraining)
which(diag(var(pranew))>0.9)
var(pranew)
pcatr
summary(pcatr)
pcatr$std
pcatr$numComp
pcatr$rotation
varper<-diag(var(pranew)/sum(diag(var(pranew)))
)
varper[1]
varper[1:2]
sum(varper[1:2])
sum(varper[1:3])
sum(varper[1:4])
sum(varper[1:6])
sum(varper[1:7])
sum(varper[1:8])
sum(varper[1:9])
newtraining<-training[,c(1,Ilname)]
newtesting<-testing[,c(1,Ilname)]
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=7)
pranew
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=7)
pcatr
pranew<-predict(pcatr,newtraining[,-1])
fitmodel<-prediect(pranew,newtraining[,-1])
fitmodel<-predict(pranew,newtraining[,-1])
newtraining
newtraining[,-1]
pranew<-predict(pcatr,newtraining[,-1])
names(training)
names(newtraining)
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
library("e1071")
install.packages("e1071")
library("e1071")
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
pratest<-predict(pcatr,newtesting[,-1])
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=2)
pranew<-predict(pcatr,newtraining[,-1])
pratest<-predict(pcatr,newtesting[,-1])
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=11)
pranew<-predict(pcatr,newtraining[,-1])
pratest<-predict(pcatr,newtesting[,-1])
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=6)
pranew<-predict(pcatr,newtraining[,-1])
pratest<-predict(pcatr,newtesting[,-1])
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=5)
pranew<-predict(pcatr,newtraining[,-1])
pratest<-predict(pcatr,newtesting[,-1])
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
pcatr<-preProcess(newtraining[,-1],method="pca",pcaComp=7)
pranew<-predict(pcatr,newtraining[,-1])
pratest<-predict(pcatr,newtesting[,-1])
fitmodel<-train(newtraining$diagnosis~.,method="glm",data=pranew)
confusionMatrix(newtesting$diagnosis,predict(fitmodel,pratest))
data(iris); library(ggplot2)
names(iris)
modFit <- train(Species ~ .,method="rpart",data=training)
inTrain <- createDataPartition(y=iris$Species,
p=0.7, list=FALSE)
training <- iris[inTrain,]
testing <- iris[-inTrain,]
modFit <- train(Species ~ .,method="rpart",data=training)
plot(modFit$finalModel, uniform=TRUE,
main="Classification Tree")
text(modFit$finalModel)
text(modFit$finalModel, use.n=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE)
text(modFit$finalModel, use.n=TRUE, all=TRUE, cex=.8)
library(rattle)
install.packages("attle)")
install.packages("attle")
library("attle")
install.packages("attle")
confusionMatrix(testing$Species,predict(modelFit,testing))#查看效率
modelFit<-train(Species ~.,method="rpart",data=training)
fancyRpartPlot(modFit$finalModel)
confusionMatrix(testing$Species,predict(modelFit,testing))#查看效率
??desrcibe
??describe
?cumcom
??cumulative
cumsum(1:10)
cumprod(1:10)
cummin(c(3:1, 2:0, 4:2))
cummax(c(3:1, 2:0, 4:2))
?bag
??bag
library(caret)
?bag
aes
?aes
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
names(segmentationOriginal)
train<-subset(segmentationOriginal,Class=Train)
table(train$Class)
train<-subset(segmentationOriginal,Case=Train)
train<-subset(segmentationOriginal,Case="Train")
train<-subset(segmentationOriginal,Cell="Train")
table(train$Case)
library(AppliedPredictiveModeling)
data(segmentationOriginal)
library(caret)
train<-subset(segmentationOriginal,Cell=="Train")
train<-subset(segmentationOriginal,segmentationOriginal$Cell=="Train")
train<-subset(segmentationOriginal,Case=="Train")
table(train$Case)
test<-subset(segmentationOriginal,Case=="Test")
table(train$Cell)
table(train$Class)
modlefit<-train(Class~.,method="rpart",data=train)
summary(molefit$finalModel)
summary(modlefit$finalModel)
length(names(train))
test<-data.frame(matrix(NA,ncol=length(names(train)),nrow=4))
View(test)
names(test)<-names(train)
test<-data.frame(matrix(0,ncol=length(names(train)),nrow=4))
names(test)<-names(train)
test$TotalIntench2[1:3,]<-c(23000,50000,57000)
test$TotalIntench2[1:3]
test$TotalIntench2[1:3,]
names(test)
test$TotalIntenCh2[1:3,]<-c(23000,50000,57000)
test$TotalIntenCh2[1:3,]
test$TotalIntenCh2[1,]
test$TotalIntenCh2
test$TotalIntenCh2[1:3]<-c(23000,50000,57000)
test$PerimStatusCh1[1:3]
test$FiberWidthCh1[1:3]<-c(10,10,8)
test$PerimStatusCh1[1:3]<-c(2,100,100)
test$FiberWidthCh1[4]<-8
test$VarIntenCh4[4]<-100
test$PerimStatusCh1[4]<-2
predict(modlefit,test)
train@Case
class(train$Case)
table(train$Case)
rep("Train",length=4)
test$Case[1:4]<-rep("Train",length=4)
predict(modlefit,test)
testpre<-predict(modlefit,test)
testpre$fit
testpre$fited
class(testpre)
str(testpre)
testpre
View(test)
test$FiberWidthCh1
test$TotalIntenCh2
test$PerimStatusCh1
test$TotalIntenCh2[1:3]<-c(23000,50000,57000)
test$FiberWidthCh1[1:3]<-c(10,10,8)
test$PerimStatusCh1[1]<-c(2)
test<-data.frame(matrix(0,ncol=length(names(train)),nrow=4))
names(test)<-names(train)
test$TotalIntenCh2[1:3]<-c(23000,50000,57000)
test$FiberWidthCh1[1:3]<-c(10,10,8)
test$PerimStatusCh1[1]<-c(2)
test$VarIntenCh4[2:3]<-c(100,100)
test$FiberWidthCh1[4]<-8
test$VarIntenCh4[4]<-100
test$PerimStatusCh1[4]<-2
testpre<-predict(modlefit,test)
test$Case[1:4]<-rep("Train",length=4)
testpre<-predict(modlefit,test)
testpre
test$TotalIntenCh2
test$FiberWidthCh1
test$PerimStatusCh1
test$VarIntenCh4
test$FiberWidthCh1
test$VarIntenCh4[
test$VarIntenCh4
test$PerimStatusCh1
test<-subset(segmentationOriginal,Case=="Test")[-3]
train<-subset(segmentationOriginal,Case=="Train")[-3]
modlefit<-train(Class~.,method="rpart",data=train)
train<-subset(segmentationOriginal,Case=="Train")[-2]
modlefit<-train(Class~.,method="rpart",data=train)
test<-data.frame(matrix(0,ncol=length(names(train)),nrow=4))
names(test)<-names(train)
test$TotalIntenCh2[1:3]<-c(23000,50000,57000)
test$FiberWidthCh1[1:3]<-c(10,10,8)
test$PerimStatusCh1[1]<-c(2)
test$VarIntenCh4[2:3]<-c(100,100)
test$FiberWidthCh1[4]<-8
test$VarIntenCh4[4]<-100
test$PerimStatusCh1[4]<-2
test$Case[1:4]<-rep("Train",length=4)
testpre<-predict(modlefit,test)
testpre
setwd("/Users/garfield/peer/courserapeer")
training<-read.csv("training.csv", na.strings=c("NA",""))
lotMiss<-(lapply(training,function(i){sum(is.na(i))})>19000)
training<-training[,!lotMiss]
training<-training[,-(1:7)]
library(caret)
namelen<-length(training)
descrCor <- cor(training[-namelen])
highlyCor<-findCorrelation(cor(training[-namelen]),cutoff = 0.80)
newtrain<-training[-namelen][,-highlyCor]
descrCor <- cor(newtrain)
training<-cbind(newtrain,training[namelen])
namelen<-length(training)
prePCA<-preProcess(training[-namelen],method="pca",thresh=0.8)
trainPC<-predict(prePCA,training[,-namelen])
names(trainPC)
train1<-cbind(trainPC,training[namelen])
names(train1)
training<-cbind(trainPC,training[namelen])
qplot(classe,PC1,data=training,geom=("boxplot","jitter”))
qplot(classe,PC1,data=training,geom=("boxplot","jitter"))
qplot(classe,PC1,data=training,geom=("boxplot","jitter"))
qplot(classe,PC1,data=training)
jetter(classe,PC1,data=training)
jitter(classe,PC1,data=training)
swirl()
swril()
library(swirl)
swirl()
plot(child~parent,galton)
